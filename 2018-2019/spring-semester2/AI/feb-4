Homework:
    - We will do some sort of randomized hill climbing

Hillclimbing Algorithm:
    - Moves in the Direction of increasing Value
        - only moves forward

    - When it reaches a peak it terminates
        - only looks at immediate neighbors
            - Though we can specify what the neighborhood is, making it much
              larger so we have more to search from


        - never backtracks or explores in parallel

    - often run multiple times with different initial values

Simulated Annealing
    - instead of picking the best move, we pick randomly

    - we have this thing called a cooling schedule
        - itially it is hot, the particle flys around freely
            - meaning that we move in random direction

        - over time it gets cooler and cooler
            - this means that the probability of moving randomly is much lower
            - then the algorithm aproaches hill climbing at this point

    - there is a chance based on some probability that we will move in a given
      direction, even if it is worse than the last one

    - algorithm
        - if the temperature is 0, return our current value

        - next is a random selected successor of current
            - if this solution is better, then we move to it
            - if it this colution is not better, then we move with some
              probability
                - this probability decreases as the temperature increases

    - you have to figure out a cooling schedule
    - you also have to figure out how we expect the probability function to
      change over time

Randomized Hillclimbing
    - We essentially use a random generator to grab a solutoin within the
      neighborhood
        - we have a non finite number of neighbors

        - the neighbors are generated by some random function

        - ex:
            s = (min(1, max(0, x+r1)), min(1, max(0, y+r2)), min(1, max(0, z+r3)))
            r1, r2, r3 = random number from [-0.05, +0.05]

            - the nieghborhood size is defined by the random numbres

    - the neighbors are what is randomized in this approach


Hill Climbing Variations:
    - we can use info from previous runs to improve our algorithm
    - we can dynamically adjust the size of the neighborhood
        - once we get closer to the peak, reduce the neighborhood size so we
          move less

    - use domain specific knowledge

* Previous algorithms
    - we have an idea of a neighborhood in all of the mentioned algorithms

Hill Climbing for State Space Search:
    - we might want to create our neighborhood not just the adjacent states,
      but 2 or 3 states down the road.
        - to really ensure that we find the goal state we need to expand the
          size of our neighborhood

*******************************************************************************
*** SWITCHING GEARS
*******************************************************************************
Games (specificially those with opponents)
    - we cannot completley generate trees for the game because they are much to
      large

    - we need some sort of evaluation function to choose what state we should
      go to

Types of Games
                                Deterministic           Chance
                            __________________________________________________
    Perfect Information     |   Chess, checkers,    |   backgammon, monopoly
                            |   tic, tac toe        |
                            |-----------------------|------------------------
    Imperfect Information   |                       |   poker
                            |________________________________________________

    - Game tree, deterministic, turns
        - you generate a game tree for the best possible moves
        - then you take the best move when your oponent takes the best move
        - or you can determine the worst based on the worst way your opponent
          could play
            - this is known as minimax
                - we assume we have the tree
                - We have a tree where we can take 3 moves at any point
                    - we either have a terminal state or something from an
                      evaluation function

                - we assume the oponent makes the best move

Properties of Minimax
    - Complete, and optimal (against an optimal opponent)

    - Time complexity
        - O(b^m) because we have to create the entire tree

    - Space complexity
        - O(bm)
        - because we do depth first search

    - we take the minimum of the leaf and propogate it up
        - then we take the max from that level and that is the branch that we
          want to take


aplha-beta:
    - we prune the results
        - get rid of those that could not be the best solution

        - this does not effect the result

Evaluation Functions:
    - Consider all of the domain specific things that would help us for a
      particular game


Non-Deterministic Games
    - for each edge we have to consider the probability of that dice roll (or
      drawing that particular card, or whatever random event)


Bridge and Card Games in General:
    - 

